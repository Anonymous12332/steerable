{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introductive notebook to the proposed network architecture that may be used for results reproduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to play with Lines dataset you can download it here:\n",
    "\n",
    "https://drive.google.com/drive/folders/1PHPHxoB4QRX7rFuYN5lMHY0vqnm3mfBZ?usp=sharing\n",
    "\n",
    "Squares dataset is located here:\n",
    "\n",
    "https://drive.google.com/drive/folders/1orleO-scD441IFMob4-ZpndeIL_imv5t?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed approach is based on a combination of two ideas: usage of Group convolutional CNNs to get equivariant tensors and usage of parameterized kernels on top of that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a PyTorch implementation of two networks using the class EquivariantNet.\n",
    "It implements DenseNet style convolutional network with different modes of equivariance:\n",
    "- none: plain cnn\n",
    "- flip: horizontal flip\n",
    "- rotation: pi/2 rotation\n",
    "- flip_rotation: horizontal flip + pi/2 rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equiv_net import EquivariantNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the parameters:\n",
    "\n",
    "numBlocks: number of convolutional blocks inside each pooling block\n",
    "\n",
    "blockSize: depth of convolutional kernels\n",
    "\n",
    "equiv_level: equivariance level of the basic GCNN network. \n",
    "\n",
    "use_reduction_before: whether to do group reduction before the application of parameterized kernel\n",
    "\n",
    "reduction: type of steerable reduction. \n",
    "\n",
    "        'average' and 'max' produces equivariant to given \n",
    "        transformation tensor (average and max group pooling)\n",
    "\n",
    "        'sobel' produces vector rotating and flipping tother with input image\n",
    "\n",
    "        'square' produces a vector rotating with 4x speed as input image\n",
    "\n",
    "        'line' produces a vector rotating with 2x speed as input image\n",
    "                                        \n",
    "k_pool_size: in case reduction uses convolution, specifies convolution size\n",
    "\n",
    "pPoolDrop: ColumnDrop rates at pooling layers\n",
    "\n",
    "pOctaveDrop: probability the entire group element tensor will be dropped at the training stage\n",
    "\n",
    "use_bn: whether Batch Norm (Group version) is used\n",
    "\n",
    "numPoolngs: Number of 2 * 2 spatial average poolings (last pooling always pools to the size 1)\n",
    "\n",
    "tag: specifies the type of parameterization kernel to apply on top of GCNN output:\n",
    "\n",
    "        'none': no convolution\n",
    "        \n",
    "        'usual': usual CNN, no specific parameterization\n",
    "        \n",
    "        'symmetrical': application of symmetrical kernel\n",
    "        \n",
    "        'line': application of a kernel simulating line orientation (outputs vector that flips if the image is flipped and *-1 if image is pi/2 rotated\n",
    "        \n",
    "        'square': kernel simulating square orientation (flips if image is flipped and not changing if the image is rotated)\n",
    "        \n",
    "        'sobel': kernel that outputs vector (rotates and flip together with the image)\n",
    "        \n",
    "use_reduction_conv: whether to use convolution reducing the tensor depth before the steerable kernel application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EquivariantNet(  numBlocks=2, \n",
    "                       blockSize=24, \n",
    "                       equiv_level='flip_rotation', \n",
    "                       use_reduction_before=True,\n",
    "                       reduction='sobel', \n",
    "                       k_pool_size=1, \n",
    "                       pPoolDrop=[0]*6, \n",
    "                       pOctaveDrop=0,\n",
    "                       use_bn=True, \n",
    "                       numPoolings=6, \n",
    "                       tag='none', \n",
    "                       use_reduction_conv=False, \n",
    "                       loss_type='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell starts the training (works on both CPU and GPU)\n",
    "\n",
    "Specify all the parameters (number of epochs, learning rate, which datasets to train on, \n",
    "which network configurations (types of equivariance and types of steerable kernels) to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import trainNetworks\n",
    "\n",
    "#train and etst batch sizes\n",
    "trainBatchSize, testBatchSize  = 16, 16\n",
    "\n",
    "#learning rate of SGD+momentum\n",
    "learning_rate, lr_decay = 1e-5, 1\n",
    "\n",
    "#number of epochs\n",
    "numEpochs = 2000\n",
    "\n",
    "#please leave it as it is\n",
    "alpha_changing, min_alpha, max_alpha = False, 1, 3\n",
    "\n",
    "#path to save model weights\n",
    "save_folder='/content/drive/MyDrive/PytorchExperiments/model_weights/' \n",
    "\n",
    "#frequency model will be evaluated and saved\n",
    "save_freq=20\n",
    "\n",
    "#List of network architectures to train\n",
    "netNames = [f\"EquivariantNet(numBlocks=2, blockSize={block_size}, equiv_level='flip_rotation', reduction='square', k_pool_size = 4, pPoolDrop=[0]*5, pOctaveDrop=0, \"\\\n",
    "            f\"use_bn=True, numPoolings=5, tag='none', use_reduction_conv=False, loss_type='cosine')\" \n",
    "            for block_size in [6]] * 4\n",
    "\n",
    "#steerable kernels\n",
    "netNames+= [f\"EquivariantNet(numBlocks=2, blockSize={block_size}, equiv_level='flip_rotation', reduction='average', k_pool_size = 4, pPoolDrop=[0]*5, pOctaveDrop=0, \"\\\n",
    "            f\"use_bn=True, numPoolings=5, tag='square_4', use_reduction_conv=False, loss_type='cosine')\" \n",
    "            for block_size in [6]] * 4\n",
    "\n",
    "#usual networks\n",
    "netNames+= [f\"EquivariantNet(numBlocks=2, blockSize={block_size}, equiv_level='none', reduction='average', k_pool_size = 4, pPoolDrop=[0]*5, pOctaveDrop=0, \"\\\n",
    "            f\"use_bn=True, numPoolings=5, tag='usual', use_reduction_conv=False, loss_type='cosine')\" \n",
    "            for block_size in [16]] * 4 * 2\n",
    "\n",
    "\n",
    "#datasets to train on\n",
    "datasets = [\"Lines_fixed_20\", \"Lines_fixed_40\", \"Lines_fixed_60\", \"Lines_fixed_80\"] * 4\n",
    "\n",
    "#whether to use data augmentations \n",
    "# []: no augmentation, \n",
    "#['flip_rotate']: images and labels are randomly flipped and rotated (8 combinations) \n",
    "#['flip']: images are flipped\n",
    "#['rotate']: images are rotated (4 variants)\n",
    "dataAugmentations = [[]]*8 + [['flip_rotate']]*4 + [[]]*4\n",
    "\n",
    "\n",
    "trainNetworks(datasets, trainBatchSize, testBatchSize, dataAugmentations, netNames, \n",
    "              learning_rate, lr_decay, numEpochs, \n",
    "              alpha_changing, min_alpha, max_alpha,\n",
    "              testRotation = False, testAddition = False, \n",
    "              save_folder=save_folder, save_freq=save_freq,\n",
    "              test_flipped=False, test_8=[True]*len(netNames), get_all_losses=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
